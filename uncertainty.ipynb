{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Estimation\n",
    "  - **0:** class\n",
    "  - **1:** x_mean\n",
    "  - **2:** x_std\n",
    "  - **3:** y_mean\n",
    "  - **4:** y_std\n",
    "  - **5:** w_mean\n",
    "  - **6:** w_std\n",
    "  - **7:** h_mean\n",
    "  - **8:** h_std\n",
    "  - **9:** conf\n",
    "  - **10:** uncertainty\n",
    "  - **11** IoU\n",
    "\n",
    "  **pred** hold all the predicitons of all images. \\\n",
    "  **p** holds all predictions of a single image. \\\n",
    "  **p2** is a single prediction in an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics.utils.ops import xywh2xyxy\n",
    "from torchvision import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(predictions_path, gt_path):\n",
    "\n",
    "    predictions = []\n",
    "    gt = []\n",
    "\n",
    "    for file in os.listdir(predictions_path):\n",
    "        prediction_file_path = os.path.join(predictions_path, file)\n",
    "        prediction_name = os.path.splitext(file)[0]\n",
    "\n",
    "        # load ensemble predictions\n",
    "        try:\n",
    "            with open(prediction_file_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                predictions.append(data)\n",
    "        # load ensemble member predictions\n",
    "        except:\n",
    "            with open(prediction_file_path, \"r\") as f:\n",
    "                p = []\n",
    "                for line in f:\n",
    "                    pred_line_data = [float(value) for value in line.split()]\n",
    "                    p.append([int(pred_line_data[0]), \n",
    "                                        pred_line_data[1], 0,\n",
    "                                        pred_line_data[2], 0,\n",
    "                                        pred_line_data[3], 0,\n",
    "                                        pred_line_data[4], 0,\n",
    "                                        pred_line_data[5]])\n",
    "            predictions.append(p)\n",
    "\n",
    "        # load ground truths\n",
    "        if gt_path:\n",
    "            with open(os.path.join(gt_path, prediction_name + \".txt\"), \"r\") as f:\n",
    "                g = []\n",
    "                for line in f:\n",
    "                    gt_line_data = [float(value) for value in line.split()]\n",
    "                    g.append(gt_line_data)\n",
    "            gt.append(g)\n",
    "\n",
    "    return predictions, gt\n",
    "\n",
    "def fuzzy(pred, std):\n",
    "    \n",
    "    for i in pred:\n",
    "\n",
    "        image = []\n",
    "\n",
    "        for p in i:\n",
    "\n",
    "            # x, y are coordinates\n",
    "            # w, h are distance\n",
    "            x, y, w, h = p[1], p[3], p[5], p[7]\n",
    "            x_std, y_std, w_std, h_std = p[2], p[4], p[6], p[8]\n",
    "\n",
    "            # add x standard diviations to the original w and h\n",
    "            w_fuzzy = w + w_std * std\n",
    "            h_fuzzy = h + h_std * std\n",
    "\n",
    "            # add the distance betwen points x,y and x,y+std to w and h\n",
    "            w_fuzzy += abs(x + x_std * std -  x)\n",
    "            h_fuzzy += abs(y + y_std * std -  y)\n",
    "\n",
    "            box1 = xywh2xyxy(torch.tensor([[x, y, w, h]], dtype=torch.float))\n",
    "            box2 = xywh2xyxy(torch.tensor([[x, y, w_fuzzy, h_fuzzy]], dtype=torch.float))\n",
    "            iou = 1 - ops.box_iou(box1, box2).numpy()[0][0]\n",
    "            p.append(iou)\n",
    "            image.append(p)\n",
    "\n",
    "def match(pred, gt):\n",
    "\n",
    "    for i, pred in enumerate(pred):\n",
    "        for p in pred:\n",
    "            for g in gt[i]:\n",
    "                box1 = xywh2xyxy(torch.tensor([[p[1], p[3] ,p[5] ,p[7]]], dtype=torch.float))\n",
    "                box2 = xywh2xyxy(torch.tensor([g[1:]], dtype=torch.float))\n",
    "                iou = ops.box_iou(box1, box2).numpy()[0][0]\n",
    "                \n",
    "                if p[0] == g[0] and iou > 0.55:\n",
    "                    p.append(iou)\n",
    "                    break\n",
    "\n",
    "def binning(pred):\n",
    "    bins = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "    bins_conf = [[] for _ in range(len(bins) - 1)]\n",
    "\n",
    "        # bin confidence scores\n",
    "    for p in pred:\n",
    "        for p2 in p:\n",
    "            for j, bin_start in enumerate(bins):\n",
    "                bin_end = bins[j + 1]\n",
    "                if bin_start <= p2[9] < bin_end:\n",
    "                    if len(p2) == 11:\n",
    "                        bins_conf[j].append((p2[9], None))\n",
    "                    else:\n",
    "                        bins_conf[j].append((p2[9], p2[11]))\n",
    "                    break\n",
    "    \n",
    "    return bins_conf\n",
    "\n",
    "def calibration(conf_binned):\n",
    "    ece = 0\n",
    "    conf_means = []\n",
    "    positives_ratios = []\n",
    "    total_length = sum(len(bin) for bin in conf_binned)\n",
    "\n",
    "    for bin in conf_binned:\n",
    "\n",
    "        if not bin:\n",
    "            continue\n",
    "\n",
    "        # mean conf per bin\n",
    "        confidence = [conf[0] for conf in bin]\n",
    "        conf_mean = np.mean(confidence)\n",
    "        conf_means.append(conf_mean)\n",
    "\n",
    "        # TP per bin\n",
    "        positives = 0\n",
    "        for p in bin:\n",
    "            if p[1]:\n",
    "                positives += 1\n",
    "        \n",
    "        positives_ratio = positives / (len(bin) + 1e-16)\n",
    "        positives_ratios.append(positives_ratio)\n",
    "        ece += 1/total_length * len(bin) * abs(positives_ratio - conf_mean)\n",
    "\n",
    "    return conf_means, positives_ratios, ece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Save Metrics\n",
    " - Loads the predictions and ground truths into two lists.\n",
    " - Adds a fuzzy uncertainty value at the end of each prediction.\n",
    " - Add a IoU score at the end for each correct prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "\n",
    "# pred, gt = load(\"YOLOv9c_predictions_0.15\\\\1\\labels\", \"datasets\\crystals\\labels\\\\test\")\n",
    "# fuzzy(pred, 1)\n",
    "# match(pred, gt)\n",
    "\n",
    "\n",
    "# pred, gt = load(\"YOLOv9c_predictions_0.01\\ensemble_10\", \"datasets\\crystals\\labels\\\\test\")\n",
    "# fuzzy(pred, 1)\n",
    "# match(pred, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINE GRAPH: ensemble marco AP50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'plots_ensemble\\line_ensemble_marco'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "ap50 = [\n",
    "    [0.51466, 0.53805, 0.54445, 0.554, 0.53853, 0.55546, 0.55116, 0.55082, 0.5433, 0.54572],  # CO\n",
    "    [0.76113, 0.74806, 0.76948, 0.7745, 0.76738, 0.76061, 0.76526, 0.76702, 0.76507, 0.76456],  # C\n",
    "    [0.63499, 0.64195, 0.67644, 0.66844, 0.68662, 0.69785, 0.69789, 0.70418, 0.69876, 0.70895],  # DC\n",
    "    [0.7561, 0.75115, 0.75418, 0.74995, 0.76367, 0.76516, 0.75868, 0.75663, 0.7628, 0.76404],  # P\n",
    "    [0.50789, 0.4748, 0.50451, 0.47635, 0.49702, 0.51582, 0.50735, 0.51933, 0.50977, 0.5166],  # CC\n",
    "    [0.35416, 0.33228, 0.35894, 0.36279, 0.37465, 0.37599, 0.37182, 0.37523, 0.37087, 0.38107]   # DO\n",
    "]\n",
    "\n",
    "class_labels = ['CO', 'C', 'DC', 'P', 'CC', 'DO']\n",
    "ensemble_numbers = list(range(1, 11))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, class_data in enumerate(ap50):\n",
    "    plt.plot(ensemble_numbers, class_data, marker='o', label=class_labels[i])\n",
    "\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('AP@50')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "plt.xticks(ensemble_numbers)\n",
    "plt.savefig(os.path.join(directory, 'ap50.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINE GRAPH: ensemble icebear AP50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'plots_ensemble\\line_ensemble_icebear'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "class_labels = ['CO', 'C', 'DC', 'P', 'CC', 'DO']\n",
    "ensemble_numbers = list(range(1, 11))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, class_data in enumerate(ap50):\n",
    "    plt.plot(ensemble_numbers, class_data, marker='o', label=class_labels[i])\n",
    "\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('AP@50')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "plt.xticks(ensemble_numbers)\n",
    "plt.savefig(os.path.join(directory, 'ap50.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINE GRAPH: ensemble marco AP50-95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'plots_ensemble\\line_ensemble_marco'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "ap50_95 = [\n",
    "    [0.37803, 0.39993, 0.41041, 0.42429, 0.41917, 0.43021, 0.43159, 0.43556, 0.43276, 0.43621],\n",
    "    [0.62568, 0.61972, 0.63969, 0.6446, 0.64719, 0.64731, 0.65138, 0.64869, 0.64919, 0.64463], \n",
    "    [0.31443, 0.3405, 0.36067, 0.35771, 0.36026, 0.36314, 0.36693, 0.3648, 0.36269, 0.37036], \n",
    "    [0.54816, 0.56127, 0.57083, 0.56616, 0.57355, 0.57781, 0.57281, 0.57242, 0.57612, 0.57656], \n",
    "    [0.46865, 0.43697, 0.46434, 0.43985, 0.45447, 0.46889, 0.45759, 0.47323, 0.45896, 0.47645],\n",
    "    [0.15201, 0.15205, 0.17925, 0.18203, 0.18873, 0.18223, 0.18251, 0.18776, 0.18347, 0.18828]   \n",
    "]\n",
    "\n",
    "class_labels = ['CO', 'C', 'DC', 'P', 'CC', 'DO']\n",
    "ensemble_numbers = list(range(1, 11))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, class_data in enumerate(ap50_95):\n",
    "    plt.plot(ensemble_numbers, class_data, marker='o', label=class_labels[i])\n",
    "\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('AP@50-95')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "plt.xticks(ensemble_numbers)\n",
    "plt.savefig(os.path.join(directory, 'ap50_95.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINE GRAPH: ensemble mAP50 and mAP50-95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'plots_ensemble\\line_ensemble_marco'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "mAP50 = [\n",
    "    0.5881560695350004,\n",
    "    0.5810491240762302,\n",
    "    0.6013339227616193,\n",
    "    0.5976730390733397,\n",
    "    0.604644946767772, \n",
    "    0.6118167600960082,\n",
    "    0.6086957300745839,\n",
    "    0.6122024801273492,\n",
    "    0.6084286872474781,\n",
    "    0.613490171224863\n",
    "]\n",
    "\n",
    "mAP50_95 = [\n",
    "    0.41449089642074044,\n",
    "    0.4184056209535339, \n",
    "    0.4375304800271527, \n",
    "    0.4357746687133396, \n",
    "    0.44055931145634075,\n",
    "    0.4449336908209816, \n",
    "    0.44380210196494635,\n",
    "    0.44707498183903294,\n",
    "    0.44386615864176915,\n",
    "    0.4487471580725686\n",
    "]\n",
    "\n",
    "ensemble_numbers = list(range(1, 11))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(ensemble_numbers, mAP50, marker='o', label='mAP@50')\n",
    "plt.plot(ensemble_numbers, mAP50_95, marker='o', label='mAP@50-95')\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('mAP')\n",
    "plt.grid(True)\n",
    "plt.xticks(ensemble_numbers)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(directory, 'map50_map50_95.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALIBRATION PLOT: model/ensemble error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'plots_uncertainty\\calibration_accuracy_conf_model_ensemble'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(1, m + 1):\n",
    "    pred, gt = load(f\"YOLOv9c_predictions_0.01\\{i}\\labels\", \"datasets\\crystals\\labels\\\\test\")\n",
    "    fuzzy(pred, 1)\n",
    "    match(pred, gt)\n",
    "\n",
    "    conf_binned = binning(pred)\n",
    "    conf_means, positives_ratios, ece = calibration(conf_binned)\n",
    "\n",
    "    plt.plot(conf_means, positives_ratios, linewidth=1, marker='o', markersize=2, label=f'Model {i} (ECE: {ece:.3f})')\n",
    "\n",
    "\n",
    "pred, gt = load(f\"YOLOv9c_predictions_0.01\\ensemble_10\", \"datasets\\crystals\\labels\\\\test\")\n",
    "fuzzy(pred, 1)\n",
    "match(pred, gt)\n",
    "conf_binned = binning(pred)\n",
    "conf_means, positives_ratios, ece = calibration(conf_binned)\n",
    "\n",
    "plt.plot(conf_means, positives_ratios, linewidth=2, marker='o', markersize=4, label=f'Ensemble (ECE: {ece:.3f})', color='black')\n",
    "plt.plot([0, 1], [0, 1], color='0.7', linestyle='--')\n",
    "plt.xlabel('Means of Binned Confidences')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title(f\"m = {i}\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join(directory, f'{i}.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALIBRATION PLOT: ensemble error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'plots_uncertainty\\calibration_accuracy_conf_ensemble'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(1, m + 1):\n",
    "    pred, gt = load(f\"YOLOv9c_predictions_0.01\\ensemble_{i}\", \"datasets\\crystals\\labels\\\\test\")\n",
    "    fuzzy(pred, 1)\n",
    "    match(pred, gt)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    conf_binned = binning(pred)\n",
    "    conf_means, positives_ratios, ece = calibration(conf_binned)\n",
    "\n",
    "    plt.plot(conf_means, positives_ratios, linewidth=2, marker='o', markersize=5,label=f'ECE: {ece:.3f}', color='black')\n",
    "    plt.plot([0, 1], [0, 1], color='0.7', linestyle='--')\n",
    "    plt.xlabel('Means of Binned Confidences')\n",
    "    plt.ylabel('Fraction of Positives')\n",
    "    plt.title(f\"m = {i}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(os.path.join(directory, f'{i}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCATTER PLOT: error_conf\n",
    "Error as a function of confidence, highlighting correct classifications (green), misclassifications (red), and the number of ensemble members (m).\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = 'plots_uncertainty\\scatter_error_conf'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(1, m + 1):\n",
    "    pred, gt = load(f\"YOLOv9c_predictions_0.01\\ensemble_{i}\", \"datasets\\crystals\\labels\\\\test\")\n",
    "    fuzzy(pred, 1)\n",
    "    match(pred, gt)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    data = [(subsub[9], subsub[10], len(subsub)) for sublist in pred for subsub in sublist if len(subsub) in {11, 12}]\n",
    "    x, y, subsub_length = zip(*data)\n",
    "    colors = ['green' if length == 12 else 'red' for length in subsub_length]\n",
    "    coefficients = np.polyfit(x, y, 1)\n",
    "    trendline = np.poly1d(coefficients)\n",
    "\n",
    "    plt.figure(dpi=500)\n",
    "    plt.scatter(x, y, c=colors, s=5)\n",
    "    plt.plot(x, trendline(x), color='black', linestyle='-', label='Trendline')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title(f\"m = {i}\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 0.45)\n",
    "    plt.savefig(os.path.join(directory, f'{i}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCATTER PLOT: error_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = 'plots_uncertainty\\scatter_error_iou'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(1, m + 1):\n",
    "    pred, gt = load(f\"YOLOv9c_predictions_0.01\\ensemble_{i}\", \"datasets\\crystals\\labels\\\\test\")\n",
    "    fuzzy(pred, 1)\n",
    "    match(pred, gt)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    data = [(subsub[11], subsub[10], len(subsub)) for sublist in pred for subsub in sublist if len(subsub) in {12}]\n",
    "    x, y, subsub_length = zip(*data)\n",
    "    colors = ['green' if length == 12 else 'red' for length in subsub_length]\n",
    "    coefficients = np.polyfit(x, y, 1)\n",
    "    trendline = np.poly1d(coefficients)\n",
    "\n",
    "    plt.figure(dpi=500)\n",
    "    plt.scatter(x, y, c=colors, s=5)\n",
    "    plt.plot(x, trendline(x), color='black', linestyle='-', label='Trendline')\n",
    "    plt.xlabel('IoU')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title(f\"m = {i}\")\n",
    "    plt.xlim(0.55, 1)\n",
    "    plt.ylim(0, 0.45)\n",
    "    plt.savefig(os.path.join(directory, f'{i}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD: marco vs coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = 'plots_uncertainty\\histogram_ood_0.15_noother'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(1, m + 1):\n",
    "\n",
    "    pred_id, _ = load(f\"YOLOv9c_predictions_0.15\\ensemble_{i}\", None)\n",
    "    pred_ood, _ = load(f\"YOLOv9c_predictions_0.15_coco\\ensemble_{i}\", None)\n",
    "    fuzzy(pred_id, 2)\n",
    "    match(pred_id, gt)\n",
    "    fuzzy(pred_ood, 2)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    error_id = []\n",
    "    error_ood = []\n",
    "    for id, ood in zip(pred_id, pred_ood):\n",
    "        for j in id:\n",
    "            if j[0] != 0 and j[0] != 5:\n",
    "                error_id.append(j[10])\n",
    "        for k in ood:\n",
    "            if k[0] != 0 and k[0] != 5:\n",
    "                error_ood.append(k[10]) \n",
    "\n",
    "    plt.figure(dpi=500)\n",
    "    bin_edges = np.linspace(0, 1, 51)[1:]\n",
    "    plt.hist(error_id, bins=bin_edges, density=True, alpha=0.5, label='In-Distribution', edgecolor='black', color='green')\n",
    "    plt.hist(error_ood, bins=bin_edges, density=True, alpha=0.5, label='Out-of-Distribution', edgecolor='black', color='red')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f\"m = {i}\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 12)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(directory, f'{i}.png'))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
